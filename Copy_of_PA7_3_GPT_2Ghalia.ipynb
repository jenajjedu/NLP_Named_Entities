{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "93b5358af5f74929b3138baf0cc88133": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4a3549b9be4c4d2594db5a374078273e",
              "IPY_MODEL_fca9fbbfec17465b8df0eb777b22f24e",
              "IPY_MODEL_0393c056f06842efbb36898aba2b7340"
            ],
            "layout": "IPY_MODEL_fba8e0d4812b475c934d47e2c7283879"
          }
        },
        "4a3549b9be4c4d2594db5a374078273e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1edc871ea3804cb78a40c7d2954fdbf7",
            "placeholder": "​",
            "style": "IPY_MODEL_f1fc5afea9a643dbaf6d989d8f3e5caf",
            "value": "Downloading: 100%"
          }
        },
        "fca9fbbfec17465b8df0eb777b22f24e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_afce10eff5074b82b061a8726d680fbe",
            "max": 1042301,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8108dcd91b904fa89ac2ba930d008acb",
            "value": 1042301
          }
        },
        "0393c056f06842efbb36898aba2b7340": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f0bf53c655e4cc08d045ae2c6a487a7",
            "placeholder": "​",
            "style": "IPY_MODEL_9d1e4ec7c852498981a288240430d10f",
            "value": " 1.04M/1.04M [00:01&lt;00:00, 741kB/s]"
          }
        },
        "fba8e0d4812b475c934d47e2c7283879": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1edc871ea3804cb78a40c7d2954fdbf7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1fc5afea9a643dbaf6d989d8f3e5caf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "afce10eff5074b82b061a8726d680fbe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8108dcd91b904fa89ac2ba930d008acb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6f0bf53c655e4cc08d045ae2c6a487a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d1e4ec7c852498981a288240430d10f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c6beb9c5cd0847f9b7960d7d1f30b36e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1969b6e6cc93430bafcbd3a184360651",
              "IPY_MODEL_c3fa0409634e48ecb082bbeeeb42cede",
              "IPY_MODEL_fda0e0d598c14618b71c795fede414ac"
            ],
            "layout": "IPY_MODEL_832d74d682a645229a7bc6c28e835c97"
          }
        },
        "1969b6e6cc93430bafcbd3a184360651": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7de869a358ae4efcaed20f75c0dab56a",
            "placeholder": "​",
            "style": "IPY_MODEL_466588acdb18465b9fda0a3dd0788d99",
            "value": "Downloading: 100%"
          }
        },
        "c3fa0409634e48ecb082bbeeeb42cede": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0360745081454d9eb5c9c5463368204e",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c21f2679a33c45bc87e13e1f91ee6791",
            "value": 456318
          }
        },
        "fda0e0d598c14618b71c795fede414ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca6fac1f6be04a459a21320d27d96c43",
            "placeholder": "​",
            "style": "IPY_MODEL_6b93c8e37557406baf8f9ee03ed0503c",
            "value": " 456k/456k [00:01&lt;00:00, 474kB/s]"
          }
        },
        "832d74d682a645229a7bc6c28e835c97": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7de869a358ae4efcaed20f75c0dab56a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "466588acdb18465b9fda0a3dd0788d99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0360745081454d9eb5c9c5463368204e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c21f2679a33c45bc87e13e1f91ee6791": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ca6fac1f6be04a459a21320d27d96c43": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b93c8e37557406baf8f9ee03ed0503c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6c42620ffea743e09855567ea6967eee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b7f9f254453843ccb36512b0eab7ac2d",
              "IPY_MODEL_5e89cc08415e40928f6cb22382afdccc",
              "IPY_MODEL_491e73d89dbe4a5189eac0966d2f05f4"
            ],
            "layout": "IPY_MODEL_c3b1ba9533374f5992fc4fb51078825e"
          }
        },
        "b7f9f254453843ccb36512b0eab7ac2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_561a4fb13f1047968e337a07116e3b75",
            "placeholder": "​",
            "style": "IPY_MODEL_9be241528c10495a835566be0f79eb55",
            "value": "Downloading: 100%"
          }
        },
        "5e89cc08415e40928f6cb22382afdccc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c160de3ab74d4ff2869103f9f3603b84",
            "max": 665,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d2f1da012a734b75b25ac61d08a1b127",
            "value": 665
          }
        },
        "491e73d89dbe4a5189eac0966d2f05f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b1fb5b90d41f4d449891b2c097825215",
            "placeholder": "​",
            "style": "IPY_MODEL_8e47f84f388042e898d3b66c74df690d",
            "value": " 665/665 [00:00&lt;00:00, 22.6kB/s]"
          }
        },
        "c3b1ba9533374f5992fc4fb51078825e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "561a4fb13f1047968e337a07116e3b75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9be241528c10495a835566be0f79eb55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c160de3ab74d4ff2869103f9f3603b84": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2f1da012a734b75b25ac61d08a1b127": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b1fb5b90d41f4d449891b2c097825215": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e47f84f388042e898d3b66c74df690d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6d88af4e66aa4ceeb967e7db12ab0c82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8196b3b4079b485287b5993a90e023af",
              "IPY_MODEL_80284d5327cc46079257674a25f6c8ac",
              "IPY_MODEL_f58836937fbb4d188d828c0e7f3f7927"
            ],
            "layout": "IPY_MODEL_f438f3eb670741f39a4fbd0513afd1da"
          }
        },
        "8196b3b4079b485287b5993a90e023af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_21505dc336044234832c03db1224cc8f",
            "placeholder": "​",
            "style": "IPY_MODEL_81aa8762099144d79942f476f8f5b869",
            "value": "Downloading: 100%"
          }
        },
        "80284d5327cc46079257674a25f6c8ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1257e1dfccd24f87b69515441400fd03",
            "max": 548118077,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_34112226a8eb4ff982b83a4404fbc016",
            "value": 548118077
          }
        },
        "f58836937fbb4d188d828c0e7f3f7927": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0794c2eee2fd42ab940b91d891c5673a",
            "placeholder": "​",
            "style": "IPY_MODEL_8dbcba384d764140848b473570f6fabf",
            "value": " 548M/548M [00:07&lt;00:00, 73.1MB/s]"
          }
        },
        "f438f3eb670741f39a4fbd0513afd1da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21505dc336044234832c03db1224cc8f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81aa8762099144d79942f476f8f5b869": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1257e1dfccd24f87b69515441400fd03": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34112226a8eb4ff982b83a4404fbc016": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0794c2eee2fd42ab940b91d891c5673a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8dbcba384d764140848b473570f6fabf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jenajjedu/NLP_Named_Entities/blob/main/Copy_of_PA7_3_GPT_2Ghalia.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKOTlwcmxmej"
      },
      "source": [
        "# GPT-2 Fine-Tuning Tutorial using raw text corpus\n",
        "\n",
        "From Rey Farhan (https://reyfarhan.com/posts/easy-gpt2-finetuning-huggingface/)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKGBoVwuhM4H"
      },
      "source": [
        "This is a simplified script for fine-tuning GPT2 using Hugging Face's [Transformers library](https://huggingface.co/transformers/) and PyTorch on raw data. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lS58Tugpg5gf"
      },
      "source": [
        "---------\n",
        "Your task is to modify this assignment on raw text of your choice (I have put Pride and Prejudice as an example below) and include 10 sample generations from your chosen text that you find interesting. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xf3Qw77SZGbS"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NmMdkZO8R6q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ec54617-83fd-4aa7-b44c-bd2d8f33c61f"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 14.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.23.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 68.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Collecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
            "\u001b[K     |████████████████████████████████| 182 kB 56.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.0.4)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.11.1 tokenizers-0.13.2 transformers-4.25.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCCeyhuDHdOu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b0ccc3f-9401-4d52-a4b8-9e8aa17ab815"
      },
      "source": [
        "import os\n",
        "import time\n",
        "import datetime\n",
        "from google.colab import drive\n",
        "\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, random_split, RandomSampler, SequentialSampler\n",
        "torch.manual_seed(42)\n",
        "\n",
        "from transformers import GPT2LMHeadModel,  GPT2Tokenizer, GPT2Config, GPT2LMHeadModel\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "satxtOn9CzgR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03f0c196-05ed-4e50-e075-d74ac0ba0509"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Dec  9 21:59:08 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   60C    P0    30W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfdCML6Parvv"
      },
      "source": [
        "# Create Training Set\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_EYFrNxr-TYb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e83daacc-addd-458d-c6a8-79a180b89614"
      },
      "source": [
        "# mount my Google Drive directory and access the training data located there\n",
        "gdrive_dir = '/content/gdrive/'\n",
        "data_dir = os.path.join(gdrive_dir, \"'My Drive'\")\n",
        "filename = 'prideAndPrejudice.txt'\n",
        "\n",
        "drive.mount(gdrive_dir, force_remount=True)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_DWAMe1FopX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0cb3ae35-0bdb-46db-e04e-52c8a3133498"
      },
      "source": [
        "# copy the data to the current Colab working directory\n",
        "!cp $data_dir/$filename ."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot stat '/content/gdrive/My Drive/prideAndPrejudice.txt': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_U3m6wr3Ahzt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "021eaf3c-9c23-44f6-d095-510356bb50a1"
      },
      "source": [
        "f=open(filename)\n",
        "docs=f.readlines()\n",
        "docs=[b.strip() for b in docs]\n",
        "docs[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['It is a truth universally acknowledged, that a single man in possession of a good fortune, must be in want of a wife.',\n",
              " 'However little known the feelings or views of such a man may be on his first entering a neighbourhood, this truth is so well fixed in the minds of the surrounding families, that he is considered the rightful property of some one or other of their daughters.',\n",
              " '\"My dear Mr. Bennet,\" said his lady to him one day, \"have you heard that Netherfield Park is let at last?\"',\n",
              " 'Mr. Bennet replied that he had not.',\n",
              " '\"But it is,\" returned she; \"for Mrs. Long has just been here, and she told me all about it.\"']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQ1oK0kXaV5p"
      },
      "source": [
        "We need to get an idea of how long our training documents are.\n",
        "\n",
        "I'm not going to use the same tokenizer as the GPT2 one, which is a [byte pair encoding tokenizer](https://blog.floydhub.com/tokenization-nlp/). Instead, I'm using a simple one just to get a rough understanding."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKsH2sU0OCQA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "ad25601d-c34b-495d-c2ff-8f444665a891"
      },
      "source": [
        "doc_lengths = []\n",
        "\n",
        "for doc in docs:\n",
        "\n",
        "    # get rough token count distribution\n",
        "    tokens = nltk.word_tokenize(doc)\n",
        "\n",
        "    doc_lengths.append(len(tokens))\n",
        "\n",
        "doc_lengths = np.array(doc_lengths)\n",
        "\n",
        "sns.distplot(doc_lengths)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f4bc6624ca0>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6P6bTItJEIj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd05ac86-a7f4-47f1-ab40-a0546e521dc8"
      },
      "source": [
        "# the max token length   \n",
        "len(doc_lengths[doc_lengths > 768])/len(doc_lengths)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0004847309743092584"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63t_69HjlwAj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75286871-9ed6-4175-f6a3-ad9282e5ecca"
      },
      "source": [
        "np.average(doc_lengths)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "69.48763936015511"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tuq5bqdr4_a6"
      },
      "source": [
        "Even though these token counts won't match up to the BPE tokenizer's, I'm confident that most lines will be fit under the 768 embedding size limit for the small GPT2 model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMml12FJGjPW"
      },
      "source": [
        "# GPT2 Tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANJhbBwdxN-b"
      },
      "source": [
        "Although the defaults take care of this,I thought I'd show that you can specify some of the special tokens. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z474sSC6oe7A",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131,
          "referenced_widgets": [
            "93b5358af5f74929b3138baf0cc88133",
            "4a3549b9be4c4d2594db5a374078273e",
            "fca9fbbfec17465b8df0eb777b22f24e",
            "0393c056f06842efbb36898aba2b7340",
            "fba8e0d4812b475c934d47e2c7283879",
            "1edc871ea3804cb78a40c7d2954fdbf7",
            "f1fc5afea9a643dbaf6d989d8f3e5caf",
            "afce10eff5074b82b061a8726d680fbe",
            "8108dcd91b904fa89ac2ba930d008acb",
            "6f0bf53c655e4cc08d045ae2c6a487a7",
            "9d1e4ec7c852498981a288240430d10f",
            "c6beb9c5cd0847f9b7960d7d1f30b36e",
            "1969b6e6cc93430bafcbd3a184360651",
            "c3fa0409634e48ecb082bbeeeb42cede",
            "fda0e0d598c14618b71c795fede414ac",
            "832d74d682a645229a7bc6c28e835c97",
            "7de869a358ae4efcaed20f75c0dab56a",
            "466588acdb18465b9fda0a3dd0788d99",
            "0360745081454d9eb5c9c5463368204e",
            "c21f2679a33c45bc87e13e1f91ee6791",
            "ca6fac1f6be04a459a21320d27d96c43",
            "6b93c8e37557406baf8f9ee03ed0503c",
            "6c42620ffea743e09855567ea6967eee",
            "b7f9f254453843ccb36512b0eab7ac2d",
            "5e89cc08415e40928f6cb22382afdccc",
            "491e73d89dbe4a5189eac0966d2f05f4",
            "c3b1ba9533374f5992fc4fb51078825e",
            "561a4fb13f1047968e337a07116e3b75",
            "9be241528c10495a835566be0f79eb55",
            "c160de3ab74d4ff2869103f9f3603b84",
            "d2f1da012a734b75b25ac61d08a1b127",
            "b1fb5b90d41f4d449891b2c097825215",
            "8e47f84f388042e898d3b66c74df690d"
          ]
        },
        "outputId": "d8a9ad6a-4a79-4e52-ff16-a727d9ffa6ab"
      },
      "source": [
        "# Load the GPT tokenizer.\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2', bos_token='<|startoftext|>', eos_token='<|endoftext|>', pad_token='<|pad|>') #gpt2-medium\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "93b5358af5f74929b3138baf0cc88133"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c6beb9c5cd0847f9b7960d7d1f30b36e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6c42620ffea743e09855567ea6967eee"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sh0XKuDvnryn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbe322ee-6047-48dc-ba2c-7c0b91ed2a9b"
      },
      "source": [
        "print(\"The max model length is {} for this model, although the actual embedding size for GPT small is 768\".format(tokenizer.model_max_length))\n",
        "print(\"The beginning of sequence token {} token has the id {}\".format(tokenizer.convert_ids_to_tokens(tokenizer.bos_token_id), tokenizer.bos_token_id))\n",
        "print(\"The end of sequence token {} has the id {}\".format(tokenizer.convert_ids_to_tokens(tokenizer.eos_token_id), tokenizer.eos_token_id))\n",
        "print(\"The padding token {} has the id {}\".format(tokenizer.convert_ids_to_tokens(tokenizer.pad_token_id), tokenizer.pad_token_id))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The max model length is 1024 for this model, although the actual embedding size for GPT small is 768\n",
            "The beginning of sequence token <|startoftext|> token has the id 50257\n",
            "The end of sequence token <|endoftext|> has the id 50256\n",
            "The padding token <|pad|> has the id 50258\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ex5O1eV-Pfct"
      },
      "source": [
        "# PyTorch Datasets & Dataloaders\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3lgZoOYkxZfx"
      },
      "source": [
        "GPT2 is a large model. Increasing the batch size above 2 has lead to out of memory problems. This can be mitigated by accumulating the gradients but that is out of scope here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scqrzmqhV__z"
      },
      "source": [
        "batch_size = 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqGMee7Isfpx"
      },
      "source": [
        "I'm using the standard PyTorch approach of loading data in using a [dataset class](https://pytorch.org/tutorials/beginner/data_loading_tutorial.html).\n",
        "\n",
        "I'm passing in the tokenizer as an argument but normally I would  instantiate it within the class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_XJVIetKN-h"
      },
      "source": [
        "class GPT2Dataset(Dataset):\n",
        "\n",
        "  def __init__(self, txt_list, tokenizer, gpt2_type=\"gpt2\", max_length=768):\n",
        "\n",
        "    self.tokenizer = tokenizer\n",
        "    self.input_ids = []\n",
        "    self.attn_masks = []\n",
        "\n",
        "    for txt in txt_list:\n",
        "\n",
        "      encodings_dict = tokenizer('<|startoftext|>'+ txt + '<|endoftext|>', truncation=True, max_length=max_length, padding=\"max_length\")\n",
        "\n",
        "      self.input_ids.append(torch.tensor(encodings_dict['input_ids']))\n",
        "      self.attn_masks.append(torch.tensor(encodings_dict['attention_mask']))\n",
        "    \n",
        "  def __len__(self):\n",
        "    return len(self.input_ids)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.input_ids[idx], self.attn_masks[idx] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89Z7aYUgpWrd"
      },
      "source": [
        "To understand how I've used the tokenizer, it's worth reading [the docs](https://huggingface.co/transformers/main_classes/tokenizer.html). I've wrapped each line in the bos and eos tokens.\n",
        "\n",
        "Every tensor passed to the model should be the same length.\n",
        "\n",
        "If the line is shorter than 768 tokens, it will be padded to a length of 768 using the padding token. In addition, an attention mask will be returned that needs to be passed to the model to tell it to ignore the padding tokens. \n",
        "\n",
        "If the line is longer than 768 tokens, it will be truncated without the eos_token. This isn't a problem."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xza_O1_rD7yh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ca43f8c-024c-49e3-b656-b52ca2ca7d2c"
      },
      "source": [
        "dataset = GPT2Dataset(docs, tokenizer, max_length=768)\n",
        "\n",
        "# Split into training and validation sets\n",
        "train_size = int(0.9 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1,856 training samples\n",
            "  207 validation samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0WeP5PREUuy"
      },
      "source": [
        "# Create the DataLoaders for our training and validation datasets.\n",
        "# We'll take training samples in random order. \n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6TKgyUzPIQc"
      },
      "source": [
        "# Finetune GPT2 Language Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFsCTp_mporB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "6d88af4e66aa4ceeb967e7db12ab0c82",
            "8196b3b4079b485287b5993a90e023af",
            "80284d5327cc46079257674a25f6c8ac",
            "f58836937fbb4d188d828c0e7f3f7927",
            "f438f3eb670741f39a4fbd0513afd1da",
            "21505dc336044234832c03db1224cc8f",
            "81aa8762099144d79942f476f8f5b869",
            "1257e1dfccd24f87b69515441400fd03",
            "34112226a8eb4ff982b83a4404fbc016",
            "0794c2eee2fd42ab940b91d891c5673a",
            "8dbcba384d764140848b473570f6fabf"
          ]
        },
        "outputId": "9c11575b-e914-4a96-e507-c314eb79085b"
      },
      "source": [
        "# I'm not really doing anything with the config buheret\n",
        "configuration = GPT2Config.from_pretrained('gpt2', output_hidden_states=False)\n",
        "\n",
        "# instantiate the model\n",
        "model = GPT2LMHeadModel.from_pretrained(\"gpt2\", config=configuration)\n",
        "\n",
        "# this step is necessary because I've added some tokens (bos_token, etc) to the embeddings\n",
        "# otherwise the tokenizer and model tensors won't match up\n",
        "model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "device = torch.device(\"cuda\")\n",
        "model.cuda()\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/548M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6d88af4e66aa4ceeb967e7db12ab0c82"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBEVY2PYSTXJ"
      },
      "source": [
        "# some parameters I cooked up that work reasonably well\n",
        "\n",
        "epochs = 5\n",
        "learning_rate = 5e-4\n",
        "warmup_steps = 1e2\n",
        "epsilon = 1e-8\n",
        "\n",
        "# this produces sample output every 100 steps\n",
        "sample_every = 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLs72DuMODJO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "851c4c6f-b8f3-49f2-c837-5baca7b9bc7e"
      },
      "source": [
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = learning_rate,\n",
        "                  eps = epsilon\n",
        "                )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-p0upAhhRiIx"
      },
      "source": [
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "# (Note that this is not the same as the number of training samples).\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "# This changes the learning rate as the training loop progresses\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = warmup_steps, \n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpt6tR83keZD"
      },
      "source": [
        "def format_time(elapsed):\n",
        "    return str(datetime.timedelta(seconds=int(round((elapsed)))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCPohrZ-CTWu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d807a0ce-938e-425d-c01b-b22d9aeaef47"
      },
      "source": [
        "total_t0 = time.time()\n",
        "\n",
        "training_stats = []\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "for epoch_i in range(0, epochs):\n",
        "\n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    total_train_loss = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_labels = batch[0].to(device)\n",
        "        b_masks = batch[1].to(device)\n",
        "\n",
        "        model.zero_grad()        \n",
        "\n",
        "        outputs = model(  b_input_ids,\n",
        "                          labels=b_labels, \n",
        "                          attention_mask = b_masks,\n",
        "                          token_type_ids=None\n",
        "                        )\n",
        "\n",
        "        loss = outputs[0]  \n",
        "\n",
        "        batch_loss = loss.item()\n",
        "        total_train_loss += batch_loss\n",
        "\n",
        "        # Get sample every x batches.\n",
        "        if step % sample_every == 0 and not step == 0:\n",
        "\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            print('  Batch {:>5,}  of  {:>5,}. Loss: {:>5,}.   Elapsed: {:}.'.format(step, len(train_dataloader), batch_loss, elapsed))\n",
        "\n",
        "            model.eval()\n",
        "\n",
        "            sample_outputs = model.generate(\n",
        "                                    bos_token_id=random.randint(1,30000),\n",
        "                                    do_sample=True,   \n",
        "                                    top_k=50, \n",
        "                                    max_length = 200,\n",
        "                                    top_p=0.95, \n",
        "                                    num_return_sequences=1\n",
        "                                )\n",
        "            for i, sample_output in enumerate(sample_outputs):\n",
        "                  print(\"{}: {}\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))\n",
        "            \n",
        "            model.train()\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)       \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epoch took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_labels = batch[0].to(device)\n",
        "        b_masks = batch[1].to(device)\n",
        "        \n",
        "        with torch.no_grad():        \n",
        "\n",
        "            outputs  = model(b_input_ids, \n",
        "#                            token_type_ids=None, \n",
        "                             attention_mask = b_masks,\n",
        "                            labels=b_labels)\n",
        "          \n",
        "            loss = outputs[0]  \n",
        "            \n",
        "        batch_loss = loss.item()\n",
        "        total_eval_loss += batch_loss        \n",
        "\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    validation_time = format_time(time.time() - t0)    \n",
        "\n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======== Epoch 1 / 5 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   100  of    928. Loss: 0.4385337233543396.   Elapsed: 0:00:55.\n",
            "0:  bipartisan\" But she took it as a mistake.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   200  of    928. Loss: 0.2442033886909485.   Elapsed: 0:01:46.\n",
            "0:  increasing_reborn_in_town. Lance of Kent, Colonel, said Colonel Pemberley, \"I am determined to stay. My father has been gone.\" Elizabeth and Bingley were very fond of her father, though no longer so dear. Bingley was still at Netherfield for the next day; Elizabeth was at Netherster for the next day. As soon as she heard that Elizabeth was gone, Colonel Pemberley went into the house without being seen, and Elizabeth returned to Netherfield on this account; but she would not be able to help them, without making a stand. Mr. Collins was not surprised; but he saw very little reason to believe that her brother could not know what Colonel Pcy would be all day for them. Long, and many many inquiries ensued, and he could tell nothing of that he was all too eagerly for Mrs. Bennet, who, however, she could tell, did not allow it to get any more. Colonel P\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   300  of    928. Loss: 0.3474106788635254.   Elapsed: 0:02:40.\n",
            "0: day an inclination of Mr. Darcy's mother, in speaking of her, and in talking with them, and in talking with them of her, and in talking with them again for weeks, weeks, or weeks, nothing happened. Lydia was a little angry to have mentioned Miss Bennets, which she had already mentioned to Jane.\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   400  of    928. Loss: 0.36857858300209045.   Elapsed: 0:03:31.\n",
            "0:  Hang the very day of the dinner, Elizabeth attended the table with a lady whom she admired, and took care of her. She looked forward to a pleasant discourse in a hall, which she did not hesitate to follow as soon as she was ready. Elizabeth began to comprehend what had passed, and was surprised at the sight of Mr. Benn, who turned away, and stared him down to her with an expression of pleasure in his eyes. The whole party followed him out. When a lady's opinion of them was expressed as soon as he passed from the table in the evening, the two girls seemed to take on a much greater part. The room was exceedingly happy for them. Elizabeth had always liked her family, she thought, and always hoped to be able to enjoy them. It was as much their enjoyment in her family as the evening after breakfast, and was the first time in a twelvemonth period where it was not at a distance from the dance; Jane had often thought of it as a\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   500  of    928. Loss: 0.31373029947280884.   Elapsed: 0:04:24.\n",
            "0:  foods\"He is the friend of every one of his family, and will certainly give such thanks. We have the most superior and most important family; and we are as well-known for it in the world.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   600  of    928. Loss: 0.17528805136680603.   Elapsed: 0:05:16.\n",
            "0:  trail\"Yes, Lady Catherine, I shall not take away the credit of having spoken to you during my letter to Colonel Bingley at Brighton, and my desire for a better relations in our house will not allow it to be so. In the whole business I shall not be surprised at what you tell me by it. I shall be glad to hear from you. What is your feelings of Miss Hurst, Mrs. Darcy? Do they have all of the right opinions? Do we not agree with them?\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   700  of    928. Loss: 0.28156453371047974.   Elapsed: 0:06:07.\n",
            "0: intend\"As I always felt that it should not be such a thing, I knew it was no such thing,\" said Mrs. Bennet. \"Your situation, your dear wife's iniquity, and your behaviour towards your daughter, your husband's inactivity with him is, I think, the reason on which your family's pride was continually expressed in the name of Mr. Bingley.\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   800  of    928. Loss: 0.3062777519226074.   Elapsed: 0:06:59.\n",
            "0:  surround\"I really dislike your opinion of yourself, and have scarcely spoken much of it. I cannot remember what the manners of that other woman in town had been. I think, however, I shall be sure you have been very handsome; but my relations are very handsome, and are quite agreeable to Mrs. Forster.\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   900  of    928. Loss: 0.28712767362594604.   Elapsed: 0:07:51.\n",
            "0:  reflex_will, however, should not have prevented her from saying that his father could not but see no evil. Mr. Bennet did not like to dance with him so much, except with a few slight accents. He could not play at them, but he was not much in love with either, and they were not to have a great advantage in dancing.\n",
            "\n",
            "  Average training loss: 0.51\n",
            "  Training epoch took: 0:08:06\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.32\n",
            "  Validation took: 0:00:17\n",
            "\n",
            "======== Epoch 2 / 5 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   100  of    928. Loss: 0.0804130807518959.   Elapsed: 0:00:51.\n",
            "0:  display\"I am sorry you did not tell me so much; but, Mr. Collins, I trust I will do my utmost.\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   200  of    928. Loss: 0.16789597272872925.   Elapsed: 0:01:43.\n",
            "0:  pastor\"You are very kind and generous. Miss Eliza is the very same.\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   300  of    928. Loss: 0.1332893669605255.   Elapsed: 0:02:35.\n",
            "0:  illicit\"I will not have so little. You will only lose the whole point. But I believe Lady Catherine might still make some mistakes, as Jane would, by marrying you.\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   400  of    928. Loss: 0.4798473119735718.   Elapsed: 0:03:26.\n",
            "0:  Liberation\"If a young man were to ask him what his feelings were then, he would not immediately know.\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   500  of    928. Loss: 0.507871687412262.   Elapsed: 0:04:18.\n",
            "0:  NamThe weather was beautiful, and every evening passed very pleasantly as usual, except on the day of her daughter's absence. But when they were gone, Elizabeth, with the girls, did not hear much; and on her leaving Netherfield, she could not help saying that she was very sorry that Bingley had not seen them again. She thought of her daughter only as Jane to Jane; and with the last of her girls, with Mrs. Hurst, was forced to leave Netherfield altogether.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   600  of    928. Loss: 0.11060294508934021.   Elapsed: 0:05:10.\n",
            "0: ION\"My dear aunt, I must confess, that I saw as you probably did, and thought myself persuaded of your excellent understanding, if I had known, before my death, that what is to be done in the militia?\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   700  of    928. Loss: 0.2488270103931427.   Elapsed: 0:06:02.\n",
            "0:  glimpse\"I shall not speak of it till your letter is finished. It will not be in the country; but _that_ shall _never_ be the case. When you tell them to come, we shall not know which will be their family. The whole party will depend upon it. I must depend on it as much as possible. Every man lives to have a son, and nothing is certain about their being married. You tell me what shall happen to _your_ family.\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   800  of    928. Loss: 0.17716871201992035.   Elapsed: 0:06:55.\n",
            "0:  Laure\"This is a proof that he is not a young man. We both know that he likes to stay up long after he has seen much of the neighbourhood.\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   900  of    928. Loss: 0.11517711728811264.   Elapsed: 0:07:46.\n",
            "0: ism\"And would it be reasonable to hope that the officers themselves are superior to the officers? And would it be reasonable to suppose that their officers should not do the same?\"\n",
            "\n",
            "  Average training loss: 0.30\n",
            "  Training epoch took: 0:08:01\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.32\n",
            "  Validation took: 0:00:17\n",
            "\n",
            "======== Epoch 3 / 5 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   100  of    928. Loss: 0.4905364513397217.   Elapsed: 0:00:52.\n",
            "0: oun\"But what did he do, pray?\" said Elizabeth; \"I am afraid he ought to be gone.\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   200  of    928. Loss: 0.17922765016555786.   Elapsed: 0:01:43.\n",
            "0:  election\"A little more of the house!\" cried Maria. \"He is not welcome at Netherfield. Your mother says that he must not come to see us.\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   300  of    928. Loss: 0.1902550756931305.   Elapsed: 0:02:35.\n",
            "0:  crazy\"This is not to be taken for an attention.\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   400  of    928. Loss: 0.421204537153244.   Elapsed: 0:03:27.\n",
            "0:  bench\"I certainly am. But you must know, my dear, that my daughters have been very little affected by us. I was only a fortnight or two from my entrance in Hertfordshire. Their father is dead. How is it possible that he should not be gone so soon as he did so well?\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   500  of    928. Loss: 0.110977403819561.   Elapsed: 0:04:19.\n",
            "0:  incorporated\"In spite of all the disadvantages which might sometimes occur, I am sure I did not suffer from the same pains. I did not hear my brother mentioned three times by Mr. Gardiner; but to be sure there were many more, it would have been much better had he not done it, if he had done it before. A little to the matter of Miss de Bourgh's appearing the way she is, I believe it may have been better. Her being seen, however, is one of the few circumstances where it can do justice to the feelings which he inspires.\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   600  of    928. Loss: 0.19973978400230408.   Elapsed: 0:05:12.\n",
            "0: Peter\"But we must keep a very good countenance and keep a very reasonable eye on the picture. If it contains any part of a lady's figure, let it be the result.\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   700  of    928. Loss: 0.27503153681755066.   Elapsed: 0:06:04.\n",
            "0: uringElizabeth was so much in love with Miss Bingley, she was unable to give up the letter without a denial; and as this answered her question, she immediately put it into her pocket-book. Mr. Darcy, who was writing with his sister, read it with great pleasure; and shortly afterwards added, \"You are quite mistaken.\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   800  of    928. Loss: 0.09476561099290848.   Elapsed: 0:06:56.\n",
            "0:  reproductive\"You are to-morrow,\" said he, \"and I must do it very well.\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   900  of    928. Loss: 0.23438940942287445.   Elapsed: 0:07:48.\n",
            "0:  zoneIt was very well done, and Mr. Collins was standing close enough to his sisters to hear the conversation.\n",
            "\n",
            "  Average training loss: 0.26\n",
            "  Training epoch took: 0:08:02\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.33\n",
            "  Validation took: 0:00:17\n",
            "\n",
            "======== Epoch 4 / 5 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   100  of    928. Loss: 0.65650475025177.   Elapsed: 0:00:52.\n",
            "0:  commits\"Certainly, not to be imputed to his being the son of a very respectable man himself, he could not be so remarkably clever and agreeable. But I am not so easily blind to the folly and dishonour of his father's pride as to suppose that he could have foreseen anything so bad or so bad as this!\"\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-83aec538089d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mbatch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0mtotal_train_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatch_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQTvJ1vRP7u4"
      },
      "source": [
        "Let's view the summary of the training process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6O_NbXFGMukX"
      },
      "source": [
        "# Display floats with two decimal places.\n",
        "pd.set_option('precision', 2)\n",
        "\n",
        "# Create a DataFrame from our training statistics.\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "\n",
        "# Use the 'epoch' as the row index.\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "# A hack to force the column headers to wrap.\n",
        "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
        "\n",
        "# Display the table.\n",
        "df_stats"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68xreA9JAmG5"
      },
      "source": [
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.xticks([1, 2, 3, 4])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GfjYoa6WmkN6"
      },
      "source": [
        "# Display Model Info"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PIiVlDYCtSq"
      },
      "source": [
        "# Get all of the model's parameters as a list of tuples.\n",
        "params = list(model.named_parameters())\n",
        "\n",
        "print('The GPT-2 model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "for p in params[0:2]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "for p in params[2:14]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "for p in params[-2:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2079Qyn8Mt8"
      },
      "source": [
        "# Saving & Loading Fine-Tuned Model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ulTWaOr8QNY"
      },
      "source": [
        "# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n",
        "\n",
        "output_dir = './model_save/'\n",
        "\n",
        "# Create output directory if needed\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "print(\"Saving model to %s\" % output_dir)\n",
        "\n",
        "# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
        "# They can then be reloaded using `from_pretrained()`\n",
        "model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
        "model_to_save.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "# Good practice: save your training arguments together with the trained model\n",
        "# torch.save(args, os.path.join(output_dir, 'training_args.bin'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqMzI3VTCZo5"
      },
      "source": [
        "!ls -l --block-size=K ./model_save/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WUFUIQ8Cu8D"
      },
      "source": [
        "!ls -l --block-size=M ./model_save/pytorch_model.bin"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxlZsafTC-V5"
      },
      "source": [
        "# Copy the model files to a directory in your Google Drive.\n",
        "!cp -r ./model_save/ $data_dir\n",
        "\n",
        "# # Load a trained model and vocabulary that you have fine-tuned\n",
        "#model = GPT2LMHeadModel.from_pretrained(output_dir)\n",
        "#tokenizer = GPT2Tokenizer.from_pretrained(output_dir)\n",
        "#model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLf6rbRglYhQ"
      },
      "source": [
        "# Generate Text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4XhewaV93-_"
      },
      "source": [
        "model.eval()\n",
        "\n",
        "prompt = \"<|startoftext|>\"\n",
        "\n",
        "generated = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0)\n",
        "generated = generated.to(device)\n",
        "\n",
        "print(generated)\n",
        "\n",
        "sample_outputs = model.generate(\n",
        "                                generated, \n",
        "                                #bos_token_id=random.randint(1,30000),\n",
        "                                do_sample=True,   \n",
        "                                top_k=50, \n",
        "                                max_length = 300,\n",
        "                                top_p=0.95, \n",
        "                                num_return_sequences=3\n",
        "                                )\n",
        "\n",
        "for i, sample_output in enumerate(sample_outputs):\n",
        "  print(\"{}: {}\\n\\n\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4LrX5H-0nAU"
      },
      "source": [
        "These aren't bad at all! Now train the model on your chosen raw text that is roughly comparable in size to pride and prejudice. \n",
        "\n",
        "(5 pts) Draw a figure for tracking train and validation losses. \n",
        "\n",
        "(5 pts) Print out some sample text from your chosen data and report 10 example generations that you think are interesting! Do your examples look like your training text?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-LRDJV1_h735"
      },
      "source": [
        "> YOUR ANSWER HERE"
      ]
    }
  ]
}